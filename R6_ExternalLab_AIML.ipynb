{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "First 5 examples now are:  [9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_oh = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY_oh = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY_oh.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "7\n",
      "2\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "for i in range(10):\n",
    "    image_index =  i\n",
    "    print(trainY[image_index]) \n",
    "    plt.imshow(trainX[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Comile the model ((We will learn about optimizers it in the next residency))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 14.6384 - acc: 0.0803 - val_loss: 14.2667 - val_acc: 0.1118\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 14.2653 - acc: 0.1124 - val_loss: 12.8182 - val_acc: 0.2024\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.8146 - acc: 0.2026 - val_loss: 12.6721 - val_acc: 0.2102\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 12.6744 - acc: 0.2101 - val_loss: 12.3903 - val_acc: 0.2247\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 12.4316 - acc: 0.2223 - val_loss: 11.9254 - val_acc: 0.2533\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 11.9252 - acc: 0.2528 - val_loss: 12.4220 - val_acc: 0.2178\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.4412 - acc: 0.2164 - val_loss: 12.6775 - val_acc: 0.2100\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 12.7089 - acc: 0.2086 - val_loss: 12.0714 - val_acc: 0.2472\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.1333 - acc: 0.2435 - val_loss: 12.0705 - val_acc: 0.2466\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.1029 - acc: 0.2444 - val_loss: 11.6110 - val_acc: 0.2699\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.5792 - acc: 0.2722 - val_loss: 12.1480 - val_acc: 0.2438\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 12.1871 - acc: 0.2410 - val_loss: 12.0107 - val_acc: 0.2511\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.0344 - acc: 0.2491 - val_loss: 12.0012 - val_acc: 0.2534\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 12.0367 - acc: 0.2506 - val_loss: 11.9111 - val_acc: 0.2575\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.9153 - acc: 0.2562 - val_loss: 11.6224 - val_acc: 0.2750\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.6809 - acc: 0.2710 - val_loss: 11.8482 - val_acc: 0.2587\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.8223 - acc: 0.2604 - val_loss: 11.4809 - val_acc: 0.2828\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.5503 - acc: 0.2790 - val_loss: 11.5590 - val_acc: 0.2767\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.5156 - acc: 0.2787 - val_loss: 11.9595 - val_acc: 0.2554\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.9991 - acc: 0.2526 - val_loss: 11.4069 - val_acc: 0.2870\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 11.4366 - acc: 0.2856 - val_loss: 11.2138 - val_acc: 0.2987\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 11.2522 - acc: 0.2964 - val_loss: 11.4156 - val_acc: 0.2849\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 11.3240 - acc: 0.2895 - val_loss: 11.8298 - val_acc: 0.2630\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.8864 - acc: 0.2594 - val_loss: 11.4095 - val_acc: 0.2871\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 11.3967 - acc: 0.2882 - val_loss: 11.1560 - val_acc: 0.3048\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.2175 - acc: 0.2999 - val_loss: 11.1290 - val_acc: 0.3037\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.0842 - acc: 0.3071 - val_loss: 11.1560 - val_acc: 0.3041\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.2204 - acc: 0.2995 - val_loss: 11.0945 - val_acc: 0.3058\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.0422 - acc: 0.3098 - val_loss: 11.1096 - val_acc: 0.3071\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.1694 - acc: 0.3026 - val_loss: 11.1014 - val_acc: 0.3044\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.0383 - acc: 0.3095 - val_loss: 11.1922 - val_acc: 0.3027\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.2628 - acc: 0.2973 - val_loss: 11.3148 - val_acc: 0.2915\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.2268 - acc: 0.2970 - val_loss: 11.6458 - val_acc: 0.2744\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.7188 - acc: 0.2698 - val_loss: 11.1855 - val_acc: 0.3015\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.1667 - acc: 0.3027 - val_loss: 10.9511 - val_acc: 0.3158\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.0013 - acc: 0.3127 - val_loss: 11.2770 - val_acc: 0.2969\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.2440 - acc: 0.2982 - val_loss: 11.1277 - val_acc: 0.3038\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.1218 - acc: 0.3045 - val_loss: 11.3835 - val_acc: 0.2899\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.3634 - acc: 0.2914 - val_loss: 11.1024 - val_acc: 0.3077\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.1644 - acc: 0.3035 - val_loss: 11.0980 - val_acc: 0.3057\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 11.0048 - acc: 0.3119 - val_loss: 11.3936 - val_acc: 0.2903\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 11.4509 - acc: 0.2866 - val_loss: 10.9597 - val_acc: 0.3160\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.9338 - acc: 0.3176 - val_loss: 10.8880 - val_acc: 0.3195\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.8961 - acc: 0.3189 - val_loss: 11.2298 - val_acc: 0.2987\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.2104 - acc: 0.3006 - val_loss: 11.0483 - val_acc: 0.3108\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 11.0896 - acc: 0.3077 - val_loss: 10.9510 - val_acc: 0.3165\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.9310 - acc: 0.3180 - val_loss: 10.8985 - val_acc: 0.3194\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 10.8995 - acc: 0.3185 - val_loss: 11.0349 - val_acc: 0.3121\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 11.0247 - acc: 0.3124 - val_loss: 10.7397 - val_acc: 0.3302\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.7555 - acc: 0.3286 - val_loss: 10.9601 - val_acc: 0.3147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f480087908>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY_oh, \n",
    "          validation_data=(testX, testY_oh), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 11.5949 - acc: 0.3195 - val_loss: 13.4160 - val_acc: 0.1128\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 11.5552 - acc: 0.1129 - val_loss: 11.1935 - val_acc: 0.1148\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.8210 - acc: 0.1155 - val_loss: 11.0805 - val_acc: 0.1129\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7968 - acc: 0.1133 - val_loss: 11.0271 - val_acc: 0.1137\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.7877 - acc: 0.1148 - val_loss: 10.9904 - val_acc: 0.1139\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7771 - acc: 0.1154 - val_loss: 10.9328 - val_acc: 0.1104\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7635 - acc: 0.1107 - val_loss: 10.9055 - val_acc: 0.1106\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.7478 - acc: 0.1114 - val_loss: 10.8937 - val_acc: 0.1119\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.7404 - acc: 0.1125 - val_loss: 10.8741 - val_acc: 0.1117\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7285 - acc: 0.1125 - val_loss: 10.8437 - val_acc: 0.1100\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7209 - acc: 0.1110 - val_loss: 10.8245 - val_acc: 0.1096\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.7050 - acc: 0.1099 - val_loss: 10.8126 - val_acc: 0.1098\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.6985 - acc: 0.1106 - val_loss: 10.8073 - val_acc: 0.1106\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 10.6929 - acc: 0.1110 - val_loss: 10.7919 - val_acc: 0.1101\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.6837 - acc: 0.1106 - val_loss: 10.7891 - val_acc: 0.1108\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.6807 - acc: 0.1113 - val_loss: 10.7668 - val_acc: 0.1093\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.6723 - acc: 0.1101 - val_loss: 10.7323 - val_acc: 0.1064\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 10.6521 - acc: 0.1074 - val_loss: 10.7200 - val_acc: 0.1059\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.6440 - acc: 0.1071 - val_loss: 10.7123 - val_acc: 0.1060\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.6365 - acc: 0.1070 - val_loss: 10.7039 - val_acc: 0.1060\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.6298 - acc: 0.1071 - val_loss: 10.6998 - val_acc: 0.1064\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 10.6268 - acc: 0.1075 - val_loss: 11.4179 - val_acc: 0.1885\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 11.3949 - acc: 0.1873 - val_loss: 10.9748 - val_acc: 0.1391\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 10.9209 - acc: 0.1402 - val_loss: 10.6215 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 10.6096 - acc: 0.1000 - val_loss: 10.6132 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.6009 - acc: 0.1000 - val_loss: 10.6055 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.5932 - acc: 0.1001 - val_loss: 10.5984 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 10.5854 - acc: 0.1001 - val_loss: 10.5917 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 10.5784 - acc: 0.1001 - val_loss: 10.5855 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 10.5720 - acc: 0.1001 - val_loss: 10.5797 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5661 - acc: 0.1001 - val_loss: 10.5741 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.5605 - acc: 0.1001 - val_loss: 10.5688 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 10.5552 - acc: 0.1001 - val_loss: 10.5638 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.5500 - acc: 0.1001 - val_loss: 10.5590 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.5451 - acc: 0.1001 - val_loss: 10.5544 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 10.5406 - acc: 0.1001 - val_loss: 10.5500 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 10.5364 - acc: 0.1001 - val_loss: 10.5457 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 10.5323 - acc: 0.1001 - val_loss: 10.5416 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5279 - acc: 0.1001 - val_loss: 10.5377 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5236 - acc: 0.1001 - val_loss: 10.5339 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.5194 - acc: 0.1001 - val_loss: 10.5303 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5157 - acc: 0.1001 - val_loss: 10.5267 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5121 - acc: 0.1001 - val_loss: 10.5233 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.5085 - acc: 0.1001 - val_loss: 10.5199 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.5050 - acc: 0.1001 - val_loss: 10.5167 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.5017 - acc: 0.1001 - val_loss: 10.5136 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 10.4985 - acc: 0.1001 - val_loss: 10.5105 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 10.4953 - acc: 0.1001 - val_loss: 10.5075 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.4920 - acc: 0.1001 - val_loss: 10.5046 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 10.4889 - acc: 0.1001 - val_loss: 10.5018 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f480f5fe80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY_oh, \n",
    "          validation_data=(testX, testY_oh), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\somduitybh046\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer=sgd_optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(64, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "#Model compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
